{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset\n",
    "Loading the MNIST dataset of handwritten digits. The dataset is separated in two for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X     => input images\n",
    "# y     => output label\n",
    "# train => training dataset\n",
    "# test  => testing dataset, after training\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          images    image_size\n",
      "X_train   60000     28x28\n",
      "y_train   60000     N/A (Label)\n",
      "X_test    10000     28x28\n",
      "y_test    10000     N/A (Label)\n"
     ]
    }
   ],
   "source": [
    "# Show the dataset size and shape\n",
    "def dataset_shape():\n",
    "    print(\"\".ljust(9, \" \"), \"images\".ljust(9), \"image_size\")\n",
    "    print(\"X_train\".ljust(9, \" \"), str(X_train.shape[0]).ljust(9, \" \"), \"x\".join([str(_) for _ in X_train.shape[1:]]))\n",
    "    print(\"y_train\".ljust(9, \" \"), str(y_train.shape[0]).ljust(9, \" \"), \"N/A (Label)\")\n",
    "    print(\"X_test\".ljust(9, \" \"), str(X_test.shape[0]).ljust(9, \" \"), \"x\".join([str(_) for _ in X_test.shape[1:]]))\n",
    "    print(\"y_test\".ljust(9, \" \"), str(y_test.shape[0]).ljust(9, \" \"), \"N/A (Label)\")\n",
    "    \n",
    "dataset_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the image from the training dataset at the given index\n",
    "def show_image_index(i):\n",
    "    plt.imshow(X_train[i], cmap=\"binary\")\n",
    "    plt.title(y_train[i])\n",
    "    plt.show()\n",
    "    \n",
    "show_image_index(0) # Show image at index 0 of the training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Normalize the input data color values from [0, 255] to [0.0, 1.0]\n",
    "\n",
    "# X_train = X_train.astype(np.float32) / 255\n",
    "# X_test = X_test.astype(np.float32) / 255 \n",
    "\n",
    "X_train = keras.utils.normalize(X_train, axis=1)\n",
    "X_test = keras.utils.normalize(X_test, axis=1)\n",
    "\n",
    "show_image_index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          images    image_size\n",
      "X_train   60000     28x28x1\n",
      "y_train   60000     N/A (Label)\n",
      "X_test    10000     28x28x1\n",
      "y_test    10000     N/A (Label)\n"
     ]
    }
   ],
   "source": [
    "# Reshape the input data to 3 dimensions for the training model\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "X_test = np.expand_dims(X_test, -1)\n",
    "\n",
    "dataset_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert label classes to one hot vectors\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_5 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                16010     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()                                                        # Sequential Model\n",
    "model.add(Conv2D(32, (3,3), input_shape=(28,28,1), activation=\"relu\"))      # Input layer\n",
    "\n",
    "model.add(MaxPool2D((2,2)))\n",
    "model.add(Conv2D(64, (3,3), activation=\"relu\"))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(10, activation=\"softmax\"))                                  # Output layer\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer=\"adam\", loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Early Stopping\n",
    "es = EarlyStopping(monitor=\"val_acc\", min_delta=0.01, patience=4, verbose=1)\n",
    "\n",
    "# Model Checkpoint\n",
    "mc = ModelCheckpoint(filepath=\"./bestmodel.h5\", monitor=\"val_acc\", verbose=1, save_best_only=True)\n",
    "\n",
    "# Packaged callbacks\n",
    "cb = [es, mc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1313/1313 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 0.9888WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 16s 12ms/step - loss: 0.0342 - accuracy: 0.9888 - val_loss: 0.0428 - val_accuracy: 0.9871\n",
      "Epoch 2/5\n",
      "1309/1313 [============================>.] - ETA: 0s - loss: 0.0281 - accuracy: 0.9908WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 17s 13ms/step - loss: 0.0281 - accuracy: 0.9908 - val_loss: 0.0426 - val_accuracy: 0.9876\n",
      "Epoch 3/5\n",
      "1311/1313 [============================>.] - ETA: 0s - loss: 0.0260 - accuracy: 0.9911WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 16s 12ms/step - loss: 0.0262 - accuracy: 0.9910 - val_loss: 0.0532 - val_accuracy: 0.9853\n",
      "Epoch 4/5\n",
      "1313/1313 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 0.9918WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 17s 13ms/step - loss: 0.0245 - accuracy: 0.9918 - val_loss: 0.0445 - val_accuracy: 0.9873\n",
      "Epoch 5/5\n",
      "1310/1313 [============================>.] - ETA: 0s - loss: 0.0219 - accuracy: 0.9925WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 16s 12ms/step - loss: 0.0219 - accuracy: 0.9925 - val_loss: 0.0402 - val_accuracy: 0.9895\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=5, validation_split=0.3, callbacks=cb)\n",
    "history.model.save(\"./bestmodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0341 - accuracy: 0.9901\n",
      "The model accuracy is 0.9901000261306763\n"
     ]
    }
   ],
   "source": [
    "model_saved = keras.models.load_model(\"./bestmodel.h5\")\n",
    "score = model_saved.evaluate(X_test, y_test)\n",
    "print(f\"The model accuracy is {score[1]}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e71cffa25b3edb8353d6b2db95c5eb591e18978b9708e48778a80f566e697ec5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
